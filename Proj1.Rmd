---
title: "MC-Proj1"
author: "Alicja Wiączkowska"
date: "2024-11-22"
output:
  pdf_document: 
    toc: yes
    toc_depth: '2'
---
\newpage
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = T)

library(data.table)
library(randtoolbox)
library(readr)
library(collapse)
```

# Testy 

W celu zbadania czy dany generator zwraca liczby pseudolosowe, które można interpretować jako realizacje rozkładu jednostajnego na pewnym zbiorze - uzyskane liczby poddaje się testom zrwacającym wynik: $p$-wartość. Zazwyczaj przy ustalonym poziomie istotności, który w tym projekcie został ustalony jako  $\alpha=0.05$ hipotezę zerową o pochodzeniu liczb pseudolosowych z zadanego rozkładu odrzuca się przy uzyskaniu $p$-wartości poniżej $\alpha$. Jest to tzw. pierwszopoziomowe (*first level testing*).

Warto jednak zauważyć, że przy prawdziwych realizacjach liczb losowych z rozkładu jednostajnego, $p$-wartości są liczbmi losowymi o rozkładzie $\mathcal U(0,1)$. Można zatem sprawdzić również hipotezę o losowości i jednostajnym rozkładzie  $p$-wartości uzyskanych przy wielokrotnym powrórzeniu *first level testing*.  Ostatecznym wynikiem będzie $p$-wartość wynikająca z przeprowadzenia tzw. testowania drugopoziomowego (*second level testing*).
   
Przy testowaniu pierwszopoziomowym test przeprowadzano na próbie wielkości $n=2^{20}$.  
  
## Frequency Monobit Test   
  
Test ten opiera się na badaniu częstości występowania zer i jedynek w zadanym ciągu bitów. 
W pierwszym kroku każdy z bitów $b_i$ jest przekształcany do elementu zbioru $\{-1,1\}$ funkcją $x_i = 2b_i+1$.
Statystyka testowa ma postać
$$T_n^{obs} = \frac{1}{\sqrt n} \sum_{i=1}^n x_i $$ 
Z Centralnego Twierdzenia Granicznego przy rosnącym $n$ statystyka ta zbiega według rozkładu do $\mathcal N(0,1)$, z czego można wywnioskować, że $p$-wartość w przybliżeniu wynosi
$$p_{val} := \mathbb P(|T_n^{teoret}| > |T_n^{obs}|) \approx \mathbb P(|N| > |T_n^{obs}|) = 2\cdot\left(1-\phi(|T_n^{obs}|)\right)$$

### Second-level testing  

Zauważmy, że dla prawdziwie losowej próby p-wartość otrzymana w teście jest zmienną loswą o rozkładzie $\mathcal{U}(0,1)$. Każdą liczbę z przedziału $(0,1)$ możemy przedstawić w systemie binarnym jako 
$$p_{val} = 0.b_1b_2b_3b_4... := \sum_{i=1}^\infty b_i\cdot2^{-i},$$
gdzie dla każdego $i\in\{1,2,3...\}$ zachodzi $b_i \in \{0,1\}$.
Weźmy obcięcie tego szeregu do długości $n$.
$$p_{val}^n =0.b_1b_2b_3b_4...b_n := \sum_{i=1}^n b_i\cdot2^{-i}.$$

Można pokazać indukcyjnie, że gdy $p_{val} \sim \mathcal U(0,1)$ to $\{b_i\}_{i=1}^n$ jest ciągiem losowych bitów dlugości $n$.

$$1^o\quad p_{val} \sim \mathcal U(0,1) \implies \mathbb P(p_{val}<2^{-1}) = \mathbb P(b_1 = 0) = \frac{1}{2} = \mathbb P(p_{val}\geq 2^{-1}) = P(b_1 = 0) $$
$$2^o \quad założenie:  \mathbb P(b_{i-1} = 0) = \frac{1}{2},\quad\quad teza: \mathbb P(b_i = 0) = \frac{1}{2}$$
$$b_i = 1 \iff p_{val} - \sum_{k=1}^i b_k\cdot2^{-k} \geq 2^{-i}$$
wartość różnicy $p_{val} - \sum_{k=1}^i b_k\cdot2^{-k}$ należy do przedziału $\left[0,2^{-(i-1)}\right]$, a ponieważ $p_{val}$ była rozłożona jednostajnie, to 
$P(b_i = 1) = \frac{1}{2}$.$\quad\quad\quad\quad\quad\quad\mathbb{C.K.D.}$ 


## Test $\chi^2$ 

Test ten opiera się  na podzieleniu zaobserwowanych wartości na $k$ przedziałów (kategorii, koszyków, kubełków) oraz porównywaniu faktycznej liczby wartości wpadających do każdego z koszyków. Przy założeniu, że obserwowane liczby pseudolosowe są niezależne, statystyka testowa jest postaci:
$$\hat\chi^2 = \sum_{i=1}^k \frac{(Y_i-np_i)^2}{np_i},$$
gdzie $Y_i$ - liczba obserwacji, które znalazły się w $i$-tej kategorii; $n$ - liczba wszystkich wygenerowanych numerów pseudolosowych, $p_i$ - teoretyczne. prawdopodobieństwo wpadnięcia pojedynczej obserwacji do $i$-tego koszyka. Statystyka $\hat\chi^2$ ma rozkład $\chi^2$ z $(k-1)$ stopniami swobody.
  
```{r chisq.test.unif}
chisq.test.unif<-function(wek, n_groups=10){
  # wek - supposed random vector
  # n_groups - number of buckets 
  group_labels <- cut(wek, breaks = seq(0, 1, length.out = n_groups+1), 
                      include.lowest = TRUE)
  levels(group_labels) <- as.character((1:n_groups))
  group_frequencies <- table(group_labels)

  expected_frequencies <- rep(length(wek) / n_groups, n_groups) 
  chi_square_result <- chisq.test(group_frequencies, 
                      p = expected_frequencies / sum(expected_frequencies))
  length(group_frequencies)
  return(chi_square_result)
}
```

```{r chisq.test.ints}
chisq.test.ints<-function(wek, M){
   n_groups = M
   # wek - supposed random vector
   # n_groups - number of buckets 
   levels(wek) <- as.character(0:(M-1))
   
   group_labels <- cut(wek, breaks = (0:M) -1, 
                       include.lowest = TRUE)
   
   levels(group_labels) <- as.character((1:n_groups -1))
   group_frequencies <- table(group_labels)
   
   expected_frequencies <- rep(length(wek) / n_groups, n_groups) 
   chi_square_result <- chisq.test(group_frequencies, 
                                   p = expected_frequencies / sum(expected_frequencies))
   length(group_frequencies)
   return(chi_square_result)
 }
```

 

## Test Pokerowy  
Test pokerowy w pierwszym kroku wymaga przyporządkowania obserwacji do $k$ kubełków (jeśli generator zwraca liczby naturalne ze zbioru$\{0,1,2,...,M-1\}$, za osobny kubełek możemy uznać każdą z możliwych do uzyskania wartości), które można interpretować jako karty. Następnie dany ciąg kart należy podzielić w piątki, a następnie każdej z nich przyporządkować układ analogiczny do tych z gry w pokera. Badane jest ile piątek spełnia jeden z poszczególnych układów pokerowych: 5 różnych kart, 4 różne karty (1 para), 3 różne karty (2 pary lub trójka), 2 różne karty (full lub kreta), 1 rodzaj karty.  
  
Następnie uzyskane wyniki są porównywane z przewidywanymi częstotliwościami teretycznymi w teście $\chi^2$.

## Test Kolmogorowa-Smirnowa  
Test Kolmogorowa-Smirnowa wiąże się z badaniem rozkładów ciągłych. Jest to test opierający się na porównywaniu dystrybuanty empirycznej z teoretyczną. 
Dystrybuantę empiryczną wyznaczyć można na podstawie obserwacji $X_1,X_2,...,X_n$ korzystając ze wzoru $\hat F(x)=\frac{1}{n} \sum_{i=1}^n\mathbf 1(X_i <x)$. 
Statystyka testowa to 
$$\hat D_n =\sqrt n\cdot \underset{x\in \mathbb R}{sup} \ | \hat F_n(x)-F(x)|.$$
Przy $n$ dążącym do nieskończoności rozkład $\hat D_n$ zbiega do znanego tzw. rozkładu Kołogorowa - Smirnowa.


# Generatory

## LCG
 
$LCG$ jest jednym z najprostszych generatorów liczb pseudolosowych ze zbioru liczb naturalnych $\{0,...,M-1\}$. Generowanie ciągu liczb $x_1,x_2...,x_N$ z $LCG(M,a,c)$ przy zadanym ziarnie $x_0$ opiera się na algorytmie:
$$ x_n = (a\cdot x_{n-1} +c)\ mod\ M .$$
Rozważone zostaną dwa przykłady tego generatora $LCG(2**10, 1, 5)$ oraz $LCG(2^{10}, 3, 7)$. Testy zostaną przeprowadzone na próbie $2^{20}$ liczb pseudolosowych. Za ziarno przyjęto $x_0=0$.

```{r LCG}
LCG<-function(n, M,a,c, x){
  # n - liczba generowanych liczb
  randoms<-numeric(n)
  for(i in 1:n){
    x = (a*x+c) %% M
    randoms[i]<-x
  }
  return(randoms)
}
```
  
  
```{r LCG data}
n=2**20
lcg1 <- LCG(n, 13,1,5, 0)
lcg2 <- LCG(n, 2^10,3,7, 0)
```

  
```{r LCG data lvl2}
n=2**15
reps = 10**3
lcg1.lv2 <- LCG(n*reps, 13,1,5, 0)
lcg2.lv2 <- LCG(n*reps, 2^10,3,7, 0)
```


```{r lvl2.p_vals}
lvl2.p_vals<-function(n, reps, randoms,test){
  # reps - powrórzenia second level testing
  # n - ilość losowanych liczb
  # randoms - vector of pseudorandoms
  # test - funkcja przeprowaąca test, np. ks.test
  p_vals=numeric(reps)
  for(r in 1:reps){
    sampl<-randoms[{(n)*(r-1)+1}:(n*r)]
    test_result <- test(sampl)
    p_vals[r]<-test_result$p.value
  }
  return(p_vals)
}
```

### LCG(13, 1, 5) 
Nie jest to dobry generator liczb pseudolosowych. Dla ziarna $x_0=0$ okres generatora wynosi $M=13$, i symuluje powtarzającą się sekwencja liczb: `r c(0,lcg1[1:12])`.Każda z liczb występuje dokładnie 1 raz, co oznacza pewną jednorodność, jednak generator jest  przewidywalny: kolejny wynik ściśle zależy od poprzeniego i nie spełnia założeń losowości.
  
#### Test $\chi^2$  

```{r lcg1 chisq 13}
lcg1u<-lcg1/13
t= chisq.test.ints(lcg1, 13)
```
  
```{r lcg1 chisq}
lcg1u<-lcg1/13
t= chisq.test.unif(lcg1u, 10)
```
  
Najpierw wygenerowano $n = 2^{20}$ liczb pseudolosowych.
W pierwszopoziomowym teście przy liczbie grup $k=M=13$ generator $LCG(13, 1, 5)$ uzyskuje w teście $\chi^2$ $p$-wartść równą 1, ponieważ każda z liczb ze zbioru $\{0,1,...,M-1\}$ występuje w każdej sekwencji dokładnie raz (w dodatku w ustlonej kolejności).

```{r lcg1 chisq lvl2}
n=2**10
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, lcg1.lv2 ,function(v){chisq.test.ints(v,13)})
t=chisq.test.unif(p_vals, 10)

```


Ze względu na ograniczenia pamięci doświadczenie testowania $n=2^{17}$ powtórzono $R=10^3$ razy, a następnie na uzyskanym wektorze $p$-wartości przeprowadzono test $\chi^2$. Test wskazał finalną $p$-wartość poniżej $2.2\cdot 10^{-16}$ zarówno dla liczby kubełków $k=13$ jak i $k=10$. Wynika to z faktu, że wszystkie $p$-wartości wskazują wartość 1, co zdecydowanie zaprzecza tezie o losowości i jednostajnym rozkładzie pierwszopoziomowych $p$-wartości na zbiorze $[0,1]$.
Według testu $\chi^2$, $LCG(13, 1, 5)$ nie można uznać za dobry generator liczb pseudolosowych.

#### Test Pokerowy   

```{r lcg1 poker}
n=2**20-1
lcg1p <- LCG(n, 13,1,5, 0)/13
t <- poker.test(lcg1p, echo=F)
```
Ciąg liczb poddany testowi pokerowemu musi mieć długość podzielną przez 5. Pierwszopoziomowe testownie wykonano zatem na próbie $n = 2^{20}-1$ = `r n` liczb pseudolosowych. Już w testowaniu pierwszopoziomowym uzyskano $p$-wartość zbliżoną do zera. Wynika to z m.in. faktu, że generator $LCG(13, 1, 5)$ nie zwrócił żadnego układu 5 ani 4 takich samych "kart".

```{r lcg1 poker lvl2 pvals}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, lcg1.lv2/13 ,function(v){poker.test(v,echo=F)})
```


```{r lcg1 poker lvl2}
t=poker.test(p_vals, echo=F)
```

W testowaniu drugopoziomowym ze względu na ograniczenia pamięci doświadczenie testownia próby wielkości $n=2^{15}-3$ = `r n`  powtórzono $R = 10^3$ razy. Również w drugopoziomowym teście otrzymano $p$-wartość zbliżoną do zera. Praktycznie wszystkie układy p-wartości zostały zakwalifikowane jako "5 takich samych kart", co oznacza, że p-wartości były sobie bardzo bliskie (i wynosiły w przybliżeniu 0). Test pokerowy jednoznacznie stwierdza, że $LCG(13, 1, 5)$ nie jest dobrym generatorem liczb losowych.

#### Test Kolmogorowa-Smirnowa  

W teście Kolmogorowa-Smirnowa odpowiednią praktyką jest wykorzystanie niepowtarzających się liczb, dlatego wielkość próby w pierwszopoziomowym teście może wynieść maksymalnie $n=13$. Będziemy badać czy liczby wygenerowane przez $LCG(13,1,5)$ po znormalizowaniu dzieleniem przez $M=13$ można traktować jako realizacje rozkładu $\mathcal U(0,1)$.


```{r lcg1 KS ,warning=F, message = F}
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
for(n in 1:13){
  t= ks.test(LCG(n, 13,1,5, 0)/13,punif)
  
  d[n,] <- unname(c(n,t$statistic, t$p.value))
}
```

Wyniki pierwszopoziomowego testu przedstawiono w tabeli. Ponieważ każda z liczb wygenerowanych przez $LCG$ występuje tyle samo razy, przy tak niewielu liczbach pseudolosowych otrzymano bardzo wysokie $p$-wartości.
```{r lcg1 ks lv1 table, ,warning=F, message = F}
knitr::kable(d, caption ="LCG(13,1,5) - first level testing")
```


```{r lcg1 KS lv2,warning=F, message=F}
reps=1000

d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
for(n in 1:13){
  pv= lvl2.p_vals(n,reps,LCG(n*reps, 13,1,5, 0)/13, function(v){ks.test(v,punif)})
  t= ks.test(pv,punif)
  d[n,] <- unname(c(n,t$statistic, t$p.value))
}
```

Natomiast w drugopoziomowym testowaniu finalne $p$-wartości w każdym przypadku były  zbliżone do zera, co było spowodowane powtarzalnością sekwencji liczb, a w skutku otrzymywaniem podobnych $p$-wartości w *first level testing*.


### LCG($2^{10}$, 3, 7)  
  
```{r}
okres = 0
Start = lcg2.lv2[1]
while(Start != lcg2.lv2[okres+2]){okres=okres+1}
rm(Start)
```
Okres tego generatora jest znacznie duższy niż w poprzednim przypadku. Dla $x_0=0$ wynosi on `r okres`. Przy próbkach mniejszych niż `r okres` uzyskane liczby pseudolosowe mogą wyglądć na relizacje rozkładu jednostajnego na $\{0,1,...,M-1\}$, jednak nadal generator ten nie przejdzie wszystkich testów.  
    
      
#### Test $\chi^2$     
  
Najpierw wygenerowano $n = 2^{20}$ liczb pseudolosowych.
W pierwszopoziomowym teście przy liczbie grup $k=10$ generator $LCG(2^{10}, 3, 7)$ uzyskuje $p$-wartść mniejszą niż $2\cdot 10^{-16}$, podbnie dla $k=32$. Wynika to z faktu, że generator mając okres długości `r okres` może wygenerować tylko tyle różnych wartości ze zbioru $2^{10}$-elementowego.  
   
```{r lcg2 chisq, warning=F}
lcg2u<-lcg2/2^10
t= chisq.test.unif(lcg2u,32)
t= chisq.test.unif(lcg2u,10)
```


```{r lcg2 chisq lvl2, warning=F}
n=2**10
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, lcg2.lv2 ,function(v){chisq.test.ints(v,13)})
t=chisq.test.ints(p_vals, 10)
```


```{r lcg2 chisq lvl2 32, warning=F}
n=2**13
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, lcg2.lv2 ,function(v){chisq.test.ints(v,13)})
t=chisq.test.ints(p_vals, 32)
```

Ze względu na ograniczenia pamięci doświadczenie testowania $n=2^{13}$ powtórzono $R=10^3$ razy, a następnie na uzyskanym wektorze $p$-wartości przeprowadzono test $\chi^2$. Test wskazał finalną $p$-wartość poniżej $2\cdot 10^{-16}$ zarówno dla liczby kubełków $k=32$ jak i $k=10$. Wynika to z faktu, że wszystkie $p$-wartości wskazują wartość bliską zeru, co zdecydowanie zaprzecza tezie o losowości i jednostajnym rozkładzie pierwszopoziomowych $p$-wartości na zbiorze $[0,1]$.
Według testu $LCG(2^{10}, 3, 7)$  nie można uznać za dobry generator liczb pseudolosowych.

#### Test Pokerowy   

```{r lcg2 poker}
n=2**20-1
lcg2p <- LCG(n, 2**10,3,7, 0)/2**10
t <- poker.test(lcg2p, echo=F)
```
 Pierwszopoziomowe testownie wykonano na próbie $n = 2^{20}-1$ = `r n` liczb pseudolosowych. Już w testowaniu pierwszopoziomowym uzyskano $p$-wartość zbliżoną do zera. Wynika to z m.in. faktu, że generator $LCG(2^{10}, 3, 7)$  nie zwrócił żadnego układu 5 takich samych "kart".

```{r lcg2 poker lvl2 pvals}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, lcg2.lv2/2^10 ,function(v){poker.test(v,echo=F)})
```


```{r lcg2 poker lvl2}
t=poker.test(p_vals, echo=F)
```

W testowaniu drugopoziomowym ze względu na ograniczenia pamięci doświadczenie testownia próby wielkości $n=2^{15}-3$ powtórzono $R = 10^3$ razy. Również w drugopoziomowym teście otrzymano $p$-wartość mozno zbliżoną do zera. Praktycznie wszystkie układy p-wartości zostały zakwalifikowane jako "5 takich samych kart", co oznacza, że p-wartości z *first level testing* były sobie bardzo bliskie (i wynosiły w przybliżeniu 0). Test pokerowy jednoznacznie stwierdza, że $LCG(2^{10}, 3, 7)$  nie jest dobrym generatorem liczb losowych.

#### Test Kolmogorowa-Smirnowa  

W teście Kolmogorowa-Smirnowa odpowiednią praktyką jest wykorzystanie niepowtarzających się liczb, dlatego wielkość próby w pierwszopoziomowym teście może wynieść maksymalnie $n=2^{10}$. Będziemy badać czy liczby wygenerowane przez $LCG(2^{10},3,7)$ po znormalizowaniu dzieleniem przez $M=2^{10}$ można traktować jako realizacje rozkładu $\mathcal U(0,1)$.


```{r lcg2 KS, warning=F }
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(i in 1:length(N)){
  t= ks.test(LCG(N[i], 2^10,3,7, 0)/2^10,punif)
  d[i,] <- unname(c(N[i],t$statistic, t$p.value))
}
```

Wyniki pierwszopoziomowego testu przedstawiono w tabeli.
```{r lcg2 ks lv1 table ,warning = F}
knitr::kable(d, caption ="LCG(2^10,3,7) - first level testing")
```
Zauważmy, że gdy wielkość próby jest liczbą ze zbioru $\{2^9, 2^{10} \}$, $p-wartość$ wynosi 1, natomiast w pozostałych przypadkach przeważnie $p-wartość$ jest mniejsza niż poziom istotności $\alpha = 0.05$.

```{r lcg2 KS lv2, warning=F}
reps=1000
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(n in 1:length(N)){
  pv= lvl2.p_vals(n,reps,LCG(N[n]*reps, 2^10,3,7, 0)/2^10, function(v){ks.test(v,punif)})
  t= ks.test(pv,punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```

W drugopoziomowym testowaniu finalne $p$-wartości w każdym przypadku były  zbliżone do zera. Zarówno *first level testing* jak i *second level testing* odrzucają tezę o losowości i jednostajnym rozkładzie pseudolosowych livczb pochodzących z generatora $LCG(2^{10}, 3, 7)$.

## GLCG

Generator $GLCG$ jest pewnym rozszerzeniem $LCG$. 
Przyjmuje ziarno $x_0,x_1,...,x_{k-1}$ i przy zadanych $M$ i $\{a_i\}_{i=1}^k$polega na wyznaczeniu kolejnuch liczb pseudolosowych na podstawie rekurecji:
$$x_n =\left( \sum_{i=1}^k a_i\cdot x_{n-i} \right)\ mod\ M $$
```{r GLCG}
GLCG<-function(n, M,a_wek, x_wek){
  # n - liczba generowanych liczb
  randoms<-numeric(n)
  x <- rev(x_wek) # uporządkowujemy indeksy malejąco
  L<- length(x)
  for(i in 1:n){
    xi = sum(a_wek*x) %% M
    randoms[i]<-xi
    x<-shift(x, n=1, fill=xi, type="lag")
  }
  return(randoms)
}
```

```{r GLCG data}
n=2^20
glcg <- GLCG(n,2**10, c(3,7,68), 1:3)
```

```{r GLCG data lv2}
n=2**17
reps = 10**3
glcg.lv2 <- GLCG(n*reps,2**10, c(3,7,68), 1:3)
```
  
```{r}
okres = 0
Start = glcg.lv2[1]
while(Start != glcg.lv2[okres+2]){okres=okres+1}
rm(Start)
```

Badaniu poddano generator $GLCG\left(M=2^{10},(a_1,a_2,a_3) = (3,7,68) \right)$ z ziarnem $(x_0,x_1,x_2)= (1,2,3)$. Ma on okres `r okres`.


#### Test $\chi^2$  
  
```{r glcg chisq}
glcgu <- glcg/ 2**10
t= chisq.test.unif(glcgu, 10)
```

  
```{r glcg chisq 32}
glcgu <- glcg/ 2**10
t= chisq.test.unif(glcgu, 32)
```
  
  
```{r glcg chisq 64}
glcgu <- glcg/ 2**10
t= chisq.test.unif(glcgu, 64)
```

Najpierw wygenerowano $n = 2^{20}$ liczb pseudolosowych.
W pierwszopoziomowym teście gdy liczba grup $k$ jest dzielnikiem liczby $M=2^{10}$  generator  uzyskuje w teście $\chi^2$ $p$-wartść równą 1. *First level testing* wydaje się potwierdzać hipotezę o losowości wygenerowanych liczb (jest nawet podejrzanie za dobry).

```{r glcg chisq lvl2}
n=2**10
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, glcg.lv2/2^10 ,function(v){chisq.test.unif(v,32)})
t=chisq.test.unif(p_vals, 10)

```



Ze względu na ograniczenia pamięci w *second level testing* doświadczenie testowania $n=2^{17}$ powtórzono $R=10^3$ razy, a następnie na uzyskanym wektorze $p$-wartości przeprowadzono test $\chi^2$. Test wskazał finalną $p$-wartość poniżej $2.2\cdot 10^{-16}$. Wynika to z faktu, że wszystkie $p$-wartości wskazują wartość 1 lub bliską 1, co zdecydowanie zaprzecza tezie o losowości i jednostajnym rozkładzie pierwszopoziomowych $p$-wartości na zbiorze $[0,1]$.
Według testu $\chi^2$, rozważanego $GLCG$ nie można uznać za dobry generator liczb pseudolosowych.

#### Test Pokerowy   

```{r glcg poker}
n=2**20-1
glcgp <- GLCG(n,2**10, c(3,7,68), 1:3)/2**10
t <- poker.test(glcgp, echo=F)
```


Ciąg liczb poddany testowi pokerowemu musi mieć długość podzielną przez 5. Pierwszopoziomowe testownie wykonano zatem na próbie $n = 2^{20}-1$ liczb pseudolosowych. Już w testowaniu pierwszopoziomowym uzyskano $p$-wartość zbliżoną do zera. Jedną z przyczyn tego wyniku może być fakt, że w pseudolosowej sekwencji ułożenie w sekwencję 5 takich samych "kart" nie wystąpiło ani razu natomiast.

```{r glcg poker lvl2 pvals}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, glcg.lv2/2**10 ,function(v){poker.test(v,echo=F)})
```


```{r glcg poker lvl2}
t=poker.test(p_vals, echo=F)
```

W testowaniu drugopoziomowym ze względu na ograniczenia pamięci doświadczenie testownia próby wielkości $n=2^{15}-3$  powtórzono $R = 10^3$ razy. Również w drugopoziomowym teście otrzymano ostateczną $p$-wartość zbliżoną do zera. Żaden z układów $p$-wartości nie został zakwalifikowane jako "5 różnych kart" ani "4 różne karty" ("1 para"), co oznacza, że pierwszopoziomowych $p$-wartości nie można uznać za realizację rozkładu $\mathcal U(0,1)$.
Test pokerowy jednoznacznie stwierdza, że rozważany $GLCG$ nie jest dobrym generatorem liczb losowych.

#### Test Kolmogorowa-Smirnowa  

W teście Kolmogorowa-Smirnowa odpowiednią praktyką jest wykorzystanie niepowtarzających się liczb, dlatego wielkość próby w pierwszopoziomowym teście może wynieść maksymalnie $n=2^{10}$. Będziemy badać czy liczby wygenerowane przez $GLCG\left(2^{10},(3,7,68)\right)$ po znormalizowaniu dzieleniem przez $M=2^{10}$ można traktować jako realizacje rozkładu $\mathcal U(0,1)$.


```{r glcg KS , warning=F}
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(n in 1:length(N)){
  t= ks.test(GLCG(N[n],2**10, c(3,7,68), 1:3)/2**10,punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```

Wyniki pierwszopoziomowego testu przedstawiono w tabeliponiższej. Uzyskane $p$-wartości są  wysokie. Nie dają podstaw do odrzucenia hipotezy o pochodzeniu wygenerowanych liczb z rozkładu jednostajnego.
```{r glcg ks lv1 table}
knitr::kable(d, caption = "GLCG(2^10,(3,7,68)) - first level testing")
```

Natomiast wyniki testowania drugopoziomowego w większości przypadków prowadzą do odrzucenia hipotezy zerowej,choć nie zawsze, o czym świadczy drugopoziomowa $p$-wartość uzyskana dla $n=2^9$.  
  
```{r glcg KS lv2,warning=F}
reps=1000
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(n in 1:length(N)){
  pv= lvl2.p_vals(n,reps,GLCG(reps*N[n],2**10, c(3,7,68), 1:3)/2**10, function(v){ks.test(v,punif)})
  t= ks.test(pv,punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```

```{r glcg ks lv2 table}
knitr::kable(d, caption ="GLCG(2^10,(3,7,68)) - second level testing")
```



## RC4(32)  
  
```{r rm lcg}
rm(glcg,glcg.lv2,glcgu, glcgp) 
```

Algorytm RC4(m) jest związany z kryptografią Polega on na zainicjalizoaniu kluczem pewnej permutacji liczb ze zbioru $\{0,1,2,...,m-1\}$, a następnie powtarzania sekwecji dalszego permutowania, podczas którego jednocześnie wybierane są konkretne liczby pseudolosowe. 

*Second level testing* można rozważać na 2 sposoby:
  
i) generująć ciąg liczb długości $R\cdot n$ 

ii) powtarzająć $R$ - krotnie losowanie $n$ liczb, ze zmienionym kluczem; kluczami będą kolejne podzbiory $[m]$.
  

```{r KSA}
m=32
#Key Schelduling Alghoritm
KSA <-function(Key, m=32){
  # przyjmuje klucz sortowania, zwraca permutację
  L=length(Key)
  S=c( 0 : (m-1)) # {0,1,..,m-1}
  j = 0
  for( i in 0:(m-1)){
       j = (j + S[i+1] + Key[i %% L +1]) %% m
       
        # swap ( S[j+1], S[i+1] )
        temp=S[j+1]
        S[j+1]<-S[i+1]
        S[i+1]<-temp
  }
   return(S)  
}

```

```{r RC4}
m = 32

RC4<-function(n, Key=NULL, seed=c(0,0), m=32){
  # n -liczba generowanych liczb losowych
  randoms = numeric(n)
  i=seed[1]; j=seed[2]
  if(is.null(Key)){ S=c( 0 : (m-1))}else{S=KSA(Key)}
  for( iter in 1:n){
    
    i = (i+1) %%m
    j = ( j+S[i+1] ) %%m  # indeksy są liczone od 1 w R 
  
    # swap ( S[j+1], S[i+1] )
    temp=S[j+1]
    S[j+1]<-S[i+1]
    S[i+1]<-temp
    
    t <- (S[i+1]+S[j+1]) %%m
    randoms[iter] <- S[t+1]
  }
  return(randoms)
}
```

```{r all_subsets}
all_subsets<-function(wek, max_len=NULL){
  if(is.null(max_len) || max_len > 2**length(wek)){
    max_len  = 2**length(wek)}
  result = list()

  for(i in 1:length(wek)){
    if(length(result)>=max_len){break}
    result_i <- combn(wek,i, simplify = F)
    resut<-append(result,result_i)
  }
  return(result)
}
```


```{r RC4 data}
n=2**20 
rc <- RC4(n, c(22,12,20,24),c(7,12),m=32)
```

```{r RC4 data lv2}
n= 2**17
reps = 10**3
rc.lv2 <- RC4(n*reps, c(22,12,20,24),c(7,12),m=32)
```

```{r RC4 1000 keys}
keys = list()

for(i in 1:32){
  if(length(keys)>=10^3){break}
  keys_i <- combn(0:31,i, simplify = F)
  keys<-append(keys,keys_i)
}
```


```{r RC4 data lv2 v2}
n= 2**17
reps = 10**3  
rc.lv2.keys <- numeric(n*reps)
for(r in 1:reps){
  rc.lv2.keys[{(n)*(r-1)+1}:(n*r)]<-RC4(n, Key=keys[[r]],m=32)
}
```

```{r Frequency Monobit Test}
freq.monobit.test<-function(bits){
  n=length(bits)
  bits[bits==0] <- -1
  S_obs = fsum(bits) / sqrt(n) #test statistic
  p_val <- 2*(1- pnorm(abs(S_obs)))
  
  result<-c(S_obs, p_val)
  names(result)<-c("Test statistic", "p-value")
  return(result)
}
```


   
```{r Konwersja int - 5bit}

int5bit<-function(x){int2bit(x)[1:5]} #dla liczb

int5bits<-function(x){ 
  # dla wektorów
  L=length(x)
  result= numeric(L*5)
  for(i in 1:L){
    result[(5*i-4) : (5*i) ] <- int5bit(x[i])
  }
  return(result)
}
```

```{r RC(32) - Frequency Monobit Test}
# first level testing
RC32_FM.test<-function( rands){
  bits <- int5bits(rands)
  return(freq.monobit.test(bits))
}
```

```{r RC(32) - Frequency Monobit Test - lvl2}
reps = 1000 # powrórzenia z second level testing
# to będzie funkcja
Ts=numeric(reps)
p_vals=numeric(reps)

for(r in 1:reps){
  RC32_FM.test #...
}


```

#### Test $\chi^2$  

```{r rc chisq 32}
rcu<-rc/32
t32= chisq.test.ints(rc, 32)
```


Najpierw wygenerowano $n = 2^{20}$ liczb pseudolosowych.
W pierwszopoziomowym teście przy liczbie grup $k=M=32$ generator $RC4(32)$ uzyskuje w teście $\chi^2$  przyzwoitą $p$-wartść równą `r t32$p.value`.

```{r rc chisq lvl2}
n=2**10
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, rc.lv2 ,function(v){chisq.test.ints(v,32)})
t=chisq.test.unif(p_vals, 10)

```
```{r}
tp=t

```


```{r rc chisq lvl2 keys}
n=2**10
reps = 10**3
p_vals.k <- lvl2.p_vals(n, reps, rc.lv2.keys ,function(v){chisq.test.ints(v,32)})
t=chisq.test.unif(p_vals, 10)

```

Ze względu na ograniczenia pamięci doświadczenie testowania $n=2^{17}$ powtórzono $R=10^3$ razy, a następnie na uzyskanym wektorze $p$-wartości przeprowadzono test $\chi^2$. Test dla metody i) wskazał finalną $p$-wartość `r tp$p.value` , natomiast dla sposobu ii) wyniosła ona poniżej $2.2\cdot 10^{-16}$. Sposób i) wydaje się lepszym na *second level testing*. Przy wybraniu go, test $\chi^2$ nie daje powodów do odrzucenia hipotezy o poprawności generatora $RC4(32)$.

#### Test Pokerowy   

```{r rc poker}
n=2**20-1
rcp <- RC4(n, c(22,12,20,24),c(7,12))/32
t <- poker.test(rcp, echo=F)
```

```{r}
t <- poker.test(rcp, echo=F)
```
Ciąg liczb poddany testowi pokerowemu musi mieć długość podzielną przez 5. Pierwszopoziomowe testownie wykonano zatem na próbie $n = 2^{20}-1$ = `r n` liczb pseudolosowych. W pierwszopoziomowym testowaniu uzyskana $p$-wartość jest malutka: `r t$p.value`. Może ona być podstawą do odrzucenia hipotezy zerowej.

```{r rc poker lvl2 pvals}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, rc.lv2/32 ,function(v){poker.test(v,echo=F)})
```


```{r rc poker lvl2 keys}
t=poker.test(p_vals, echo=F)
```
W testowaniu drugopoziomowym ze względu na ograniczenia pamięci doświadczenie testownia próby wielkości $n=2^{15}-3$ = `r n`  powtórzono $R = 10^3$ razy.

Dla podejścia i) rówineż drugopoziomowy test zwraca małą $p$-wartość - wynoszącą `r t$p.value`. Wynik ten osttecznie może prowadzić do odrzucenia hipotezy zerowej.

```{r rc poker lvl2 pvals keys}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, rc.lv2.keys/32 ,function(v){poker.test(v,echo=F)})
```


```{r rc poker lvl2}
t=poker.test(p_vals, echo=F)
```
Natomiast dla podejścia drugiego uzyskana $p$-wartość była zaskakująco wysoka, bo aż `r t$p.value`.

Generator $RC4(32)$ niestetynie przeszedł testu pokerowego.

#### Test Kolmogorowa-Smirnowa  

W teście Kolmogorowa-Smirnowa odpowiednią praktyką jest wykorzystanie niepowtarzających się liczb, dlatego wielkość próby w pierwszopoziomowym teście może wynieść maksymalnie $n=32$. Będziemy badać czy liczby wygenerowane przez $RC4(32)$ po znormalizowaniu dzieleniem przez $M=32$ można traktować jako realizacje rozkładu $\mathcal U(0,1)$.


```{r rc KS , warning = F}
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N=5:32
for(n in 1:length(N)){
  t= ks.test(RC4(N[n], c(22,12,20,24),c(7,12))/32,punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```

Wyniki pierwszopoziomowego testu przedstawiono w tabeli. Dla każdej wielkości próby $n$ generator $RC4(32)$ przechodzi test Kolmogorowa-Smirnowa.

```{r rc ks lv1 table, message=F}
knitr::kable(d, caption ="RC4(32) - KS - first level testing")
```

Następnie przeprowadzono *second level testing* korzstając ze sposobu ii). Finalne $p$-wartości w każdym przypadku wyszły niesatysfakcjonująco małe. Nie jest to jednak słabość generatora, lecz problem ten został najprawdopodobniej spowodowany faktem, że prawdziwa dystrybuanta $RC4(32)$ nawet po zrzutowaniu liczb na przedział [0,1] nie dąży do dystrybuanty rozkładu $\mathcal U(0,1)$, lecz jest schodkowa.
```{r rc KS lv2,warning=F}
reps=1000
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
for(n in 1:32){
  pv= lvl2.p_vals(n,reps,RC4(n*reps, c(22,12,20,24),c(7,12))/32, function(v){ks.test(v,punif)})
  t= ks.test(pv,punif)
  d[n,] <- unname(c(n,t$statistic, t$p.value))
}
```

```{r rc ks lv2 table, message=F}
knitr::kable(d, caption ="RC4(32) - KS - second level testing")
```






## Mersenne Twister

Algorytm ten jest domyślnym generatorem liczb losowych w Pythonie lub R. Opiera się na przyjęciu za okres tzw. liczby pierwszej Mersenne'a. Generator został zaprojektowany z myślą o metodach Monte Carlo i innych symulacjach statystycznych. Jest on uważany za szybki i skuteczny generator liczb pseudolosowych.

```{r MT data}
mt <- runif(2^20)
```

```{r MT data lv2}
n= 2**17
reps = 10**3
mt.lv2 <- runif(n*reps)
```

#### Test $\chi^2$  
```{r mt chisq 10}

tp= chisq.test.unif(mt, 10)
```
  
```{r mt chisq 16}

t= chisq.test.unif(mt, 16)

```
  Najpierw wygenerowano $n = 2^{20}$ liczb pseudolosowych.
W pierwszopoziomowym teście dla $k=16$ uzyskano $p$-wartość `r t$p.value`. Dla $k\in \{32, 64\}$ uzyskano $p$-wartość równą 1. Wyniki te nie prowadzą do odrzucenia hipotezy o losowości i jednostajnym rozkładzie uzyskanych liczb. Jednkże $p$-wartość uzyskana dla $k=10$ wyniosła `r tp$p.value`, co jest bardzo małą liczbą. 

```{r mt chisq lvl2}
n=2**17
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, mt.lv2/2^10 ,function(v){chisq.test.unif(v,10)})
t=chisq.test.unif(p_vals, 10)

```

```{r}
t=chisq.test.unif(p_vals, 32)

```

```{r mt chisq lvl2 32}
n=2**17
reps = 10**3
p_vals <- lvl2.p_vals(n, reps, mt.lv2/2^10 ,function(v){chisq.test.unif(v,32)})
t=chisq.test.unif(p_vals, 10)

```

Ze względu na ograniczenia pamięci w *second level testing* doświadczenie testowania $n=2^{17}$ powtórzono $R=10^3$ razy, a następnie na uzyskanym wektorze $p$-wartości przeprowadzono test $\chi^2$ z $k=10$ i $k=32$ kubełkami. Niestety test wskazał, że finalne $p$-wartość  wyniosły poniżej $2.2\cdot 10^{-16}$. Problem ten wynika prawdopodobnie z nieoptyalnego doboru kubełków. 

 
#### Test Pokerowy   

```{r mt poker}
n=2**20-1
mtp <- runif(n)
t <- poker.test(mtp, echo=F)
```

Ciąg liczb poddany testowi pokerowemu musi mieć długość podzielną przez 5. Pierwszopoziomowe testownie wykonano zatem na próbie $n = 2^{20}-1$ liczb pseudolosowych. W *first level testing* otrzymano $p$-wartość  `r t$p.value`, kóra  nie nie daje podstaw do zaprzeczenia hipotezie zerowej o losowości i jednostajnym rozkładzie wygenerowanych liczb.

```{r mt poker lvl2 pvals}
n = 2^15-3
reps = 10^3
p_vals <- lvl2.p_vals(n, reps, mt.lv2 ,function(v){poker.test(v,echo=F)})
```

  
```{r mt poker lvl2}
t=poker.test(p_vals, echo=F)
```

W testowaniu drugopoziomowym ze względu na ograniczenia pamięci doświadczenie testownia próby wielkości $n=2^{15}-3$  powtórzono $R = 10^3$ razy. Tym razem uzyskano dużą $p$-wartość  wynoszącą`r t$p.value`, co nie odrzuca hipotezy zerowej. Jest to spodziewany wynik.

Test pokerowy zatem nie wykrywa żadnych nieprawidłowości w generatorze MT.  

#### Test Kolmogorowa-Smirnowa  

```{r mt KS , warning=F}
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(n in 1:length(N)){
  t= ks.test(runif(N[n]),punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```


Algorytm Mersenne Twister bardzo dobrze poradził sobie z tym testem.
Wyniki pierwszopoziomowego testu przedstawiono w tabeli poniższej. Uzyskane $p$-wartości są  dostatecznie wysokie i dają podstaw do odrzucenia hipotezy o pochodzeniu wygenerowanych liczb z rozkładu jednostajnego. 

```{r mt ks lv1 table}
knitr::kable(d, caption = "MT - KS test - first level testing ")
```

Natomiast wyniki testowania drugopoziomowego w większości przypadków również są satysfakcjonujące, żadna z nich nie prowadzi do odrzucenia hipotezy zerowej. Szczegóły są widoczne poniżej.
  
```{r mt KS lv2,warning=F}
reps=1000
d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('n','statystyka testowa', 'p-wartość')
N= 2^(3:10)
for(n in 1:length(N)){
  pv= lvl2.p_vals(n,reps,runif(reps*N[n]), function(v){ks.test(v,punif)})
  t= ks.test(pv,punif)
  d[n,] <- unname(c(N[n],t$statistic, t$p.value))
}
```

```{r mt ks lv2 table}
knitr::kable(d, caption =" MT - KS test - second level testing")
```








# Liczby niewymierne 

W tej części pracy zbadane zostanie czy kolejne bity rozwinięcia dwójkowego liczb niewymiernych: $\pi$, $e$ oraz $\sqrt 2$ można traktować jako pewien generator liczb pseudolosowych.
Wykorzystantego zostanie *Frequency Monobit* test służący do badania losowości ciągów bitów.


```{r pobieranie dnych z pliku, message=FALSE}
import_bits<-function(path){
  data <-read_csv(path,col_names = FALSE)
  data <- data$X1
  bits <- as.numeric(unlist(strsplit(data,"")))
  return(bits)
}
Pi_bits <- import_bits("https://www.math.uni.wroc.pl/~rolski/Zajecia/data.pi")
e_bits <- import_bits("https://www.math.uni.wroc.pl/~rolski/Zajecia/data.e")
sqrt2_bist <- import_bits("https://www.math.uni.wroc.pl/~rolski/Zajecia/data.sqrt2")
```



```{r irrationals FMT -lv1}
irrationals_FM.test<-function(n, irrational){
  bits<-irrational[1:n]
  return(freq.monobit.test(bits))
}
```


```{r irrationals FMT -lv2 p-vals}
# reps - powrórzenia second level testing
# n - ilość losowanych liczb

irrationals_FM.test.p_vals<-function(n, reps, irrational){
  Ts=numeric(reps)
  p_vals=numeric(reps)
  for(r in 1:reps){
    bits<-irrational[{(n)*(r-1)+1}:(n*r)]
    test <- freq.monobit.test(bits)
    Ts[r]<-test[[1]]
    p_vals[r]<-test[[2]]
  }
  return(p_vals)
}
```


```{r floats 2 bits}
float2bits <- function(wek, len){
  #len - length of bit vector for single float
  reps=length(wek)
  bits =  numeric(len*reps)
  for( r in 1:reps){
    t=wek[r]
    for(i in 1:len){
      if(t >= 2**(-i)){
        bits[i + (r-1)*len] <- 1
        t = t- 2**(-i)
      }
      if(t<= 0){break}
    }
  }
  return(bits)
}
```


```{r irrationals FMT -lv2}
irrationals_FM.test.lvl2<-function(n, reps, irrational, len){
  # n - number of random numbers
  # reps - number of 2nd lvl test repetitions
  # len - length of bit vector for single float
  p_vals <- irrationals_FM.test.p_vals(n, reps, irrational)
  p_bits <- float2bits(p_vals, len)
  return(freq.monobit.test(p_bits))
}
```

## Bity $\pi$ - Frequency Monobit Test

```{r Pi FM test wynik}
n=2**20
pi_test <-irrationals_FM.test(n, Pi_bits)
```

Dla pierwszych $n$ = `r length(Pi_bits)` wyrazów liczby $\pi$ w zapisie bitowym $p$-wartość uzyskana we *Frequency Monobit* Teście wyniosła `r pi_test[[2]]`. Wynik ten sugeruje, że nie ma podstaw by odrzucać hipotezę o losowości badanych bitów.

```{r Pi FM test wynik 1000}
reps = 10^3
n = floor(length(Pi_bits)/reps)
pi_test <-irrationals_FM.test(n, Pi_bits)
```
Podobnie przy rozpatrzeniu mniejszej próby pierwszych $n$ = `r n` bitów z rozwinięcia liczby $\pi$ otrzymano $p$-wartość `r pi_test[[2]]`, która również nie zaprzecza hipotezie o losowości i jednostajnym rozkładzie bitów.

Ponieważ plik źródłowy zawiera jedynie `r length(Pi_bits)` bitów, podczas przeprowadzania *second-level testing* doświadczenie testowania ciągu długości $n$ = `r n` powrórzono $R= 10^3$ razy. Następnie aby na uzyskanych w ten sposób $p$-wartościach wykonać *Frequency Monobit Test*,  każdą z nich zapisano jako szereg bitów i wybrano pierwsze $k$ z nich (przekształcając funkcją $f_k$):
$$f_k:[0,1]\rightarrow\{0,1\}^k  \quad\quad\quad
f_k(p_{val}) = f_k\left(\sum_{i=1}^\infty b_i\cdot 2^{-i}\right) = (b_1,b_2,..,b_k), $$
a następnie uzyskane w ten sposób wektory połączono jeden, który poddano testowaniu. Wyniki dla wybranych $k$ przedstawiono w poniższej tabeli.

```{r Pi FM test wynik lvl2}
reps = 10^4
n = floor(length(Pi_bits)/reps)

d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('Bts len','Test statistic', 'p-value')
lens = c(1,2,3,4,5,6,7,8,9,10,11)
for(i in 1:length(lens)){
  len=lens[i]
  t = irrationals_FM.test.lvl2(n, reps, Pi_bits, len)
  d[i,] <- unname(c(len,t)) 
}
```

```{r Pi FM test wynik lvl2 table}
d$'p-value' <- as.character(signif(d$'p-value'))
d[d$'p-value' =='0',3] <- '0.0000000'
colnames(d) <- c('k - długość 1 wektora bitów', "statystyka testowa", 'p-wartość')
knitr::kable(d, caption = "second level testiong - pi")

```


```{r Pi FM test wynik lvl2 chi sq}
Pi_p_vals = irrationals_FM.test.p_vals(n, reps, Pi_bits)
Pi_p_vals_chisq = chisq.test.unif(Pi_p_vals,10)
```

Uzyskane $p$-wartości w testowniu drugopoziomowym są bardzo małe, w niektórych przypadkach autmatycznie zaokrąglone do zera. Przy ustalonym poziomie istotności $\alpha = 0.05$ hipoteza zerowa zakładająca, że $p$-wartości pochodzące z pierwszopoziomowego testowania pochodzą z rozkładu $\mathcal U(0,1)$ zostanie odrzucona dla wszystkich $k$.

Również po poddaniu testowi $\chi^2$ z 10 jednakowymi kubełkami badanych $p$-wartości pochodzących z pierwszopoziomowego testowania *Frequency Monobit* testem, otrzymano ostateczną $p$-wartość wynoszącą mniej niż $2.2\cdot10^{-16}$.

Można zatem stwierdzić, że również w tym przypadku, mimo dobrych wyników uzyskanych podczas *first level testing*, ostatecznie należy uznać, że bitów liczby $\pi$ nie można traktować jako dobry generator liczb z rozkładu jednostajnego na zbiorze {0,1}, co wynika jednoznacznie z *second-level testing*. 



## Bity $e$ - Frequency Monobit Test

```{r e FM test wynik}
n=2**20
e_test <-irrationals_FM.test(n, e_bits)
```

Dla pierwszych $n$ = `r length(e_bits)` wyrazów liczby $e$ w zapisie bitowym $p$-wartość uzyskana we *Frequency Monobit* Teście była wysoka - wyniosła `r e_test[[2]]`. Wynik ten nie daje podstaw do stwierdzenia, że bity pochodzące z rozwnięcia dwójkowego $e$ nie są losowymi bitami rozłożonymi jednostajnie na {0,1}.

```{r e FM test wynik 1000}
reps = 10^3
n = floor(length(e_bits)/reps)
e_test <-irrationals_FM.test(n, e_bits)
```
Przy rozpatrzeniu mniejszej próby pierwszych $n$ = `r n` bitów z rozwinięcia liczby $e$ otrzymano znacznie mniejszą $p$-wartość `r e_test[[2]]`, która jednak przy istotności $\alpha=0.05$ nie prowadzi do odrzucenia hipotezy o pochodzeniu rozważanych bitów z rozkładu jednostajnego na {0,1}.

Ponieważ plik źródłowy zawiera jedynie `r length(e_bits)` bitów, podczas przeprowadzania *second-level testing* doświadczenie testowania ciągu długości $n$ = `r n` powrórzono $R= 10^3$. Następnie aby na uzyskanych w ten sposób $p$-wartościach wykonać *Frequency Monobit Test*,  każdą z nich zapisano jako szereg bitów i wybrano pierwsze $k$ z nich (jak wcześniej przekształcając funkcją $f_k$),a następnie uzyskane w ten sposób wektory połączono jeden, na którym przeprowadzono test. Wyniki dla wybranych $k$ przedstawiono w poniższej tabeli.

```{r e FM test wynik lvl2}
reps = 10^4
n = floor(length(e_bits)/reps)

d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('Bts len','Test statistic', 'p-value')
lens = c(1,2,3,4,5,6,7,8,9,10,11)
for(i in 1:length(lens)){
  len=lens[i]
  t = irrationals_FM.test.lvl2(n, reps, e_bits, len)
  d[i,] <- unname(c(len,t)) 
}
```

```{r e FM test wynik lvl2 table}
d$'p-value' <- as.character(signif(d$'p-value'))
d[d$'p-value' =='0',3] <- '0.0000000'
colnames(d) <- c('k - długość 1 wektora bitów', "statystyka testowa", 'p-wartość')

knitr::kable(d, caption = "second level testiong - e" )

```


```{r e FM test wynik lvl2 chi sq}
e_p_vals = irrationals_FM.test.p_vals(n, reps, e_bits)
e_p_vals_chisq = chisq.test.unif(e_p_vals,10)
```

Ostatecznie uzyskane $p$-wartości są małe, w niektórych przypadkach tak małe, że zostały autmatycznie zaokrąglone do zera. Przy ustalonym poziomie istotności $\alpha = 0.05$ Hipoteza zerowa o losowości $p$-wartości pochodzących z pierwszopoziomowego testowania zostanie odrzucona we wszystkich przypadkach poza $k=1$.

Ponadto gdy $p$-wartości otrzymane podczas pierwszopoziomowego testowania poddano testowi $\chi^2$ z 10 jednakowymi kubełkami otrzymano ostateczną $p$-wartość wynoszącą mniej niż $2.2\cdot10^{-16}$.

Można zatem stwierdzić, że mimo dobrych wyników uzyskanych podczas *first level testing*, ostatecznie należy uznać, że bitów liczby $e$ nie można traktować jako dobry generator liczb z rozkładu jednostajnego na zbiorze {0,1}.


## Bity $\sqrt 2$ - Frequency Monobit Test

```{r sqrt2 FM test wynik}
n=2**20
sq2_test <-irrationals_FM.test(n, sqrt2_bist)
```

Dla pierwszych $n$ = `r length(sqrt2_bist)` wyrazów liczby $\sqrt 2$ w zapisie bitowym po przeprowadzeniu *Frequency Monobit* Tesu, uzyskana $p$-wartość  wyniosła aż `r sq2_test[[2]]` co sugeruje, że nie ma podstaw do odrzucenia hipotezy o pochodzeniu badanych bitów z rozkładu jednostajnego na {0,1}.

```{r sqrt2 FM test wynik_1000}
reps = 10^3
n = floor(length(sqrt2_bist)/reps)
sq2_test <-irrationals_FM.test(n, sqrt2_bist)
```
Podobnie przy rozpatrzeniu mniejszej próby pierwszych $n$ = `r n` bitów z rozwinięcia liczby $\sqrt 2$ otrzymano $p$-wartość `r sq2_test[[2]]`, która również nie zaprzecza hipotezie o losowości bitów.

Ponieważ plik źródłowy zawiera jedynie `r length(sqrt2_bist)` bitów, podczas przeprowadzania *second-level testing* doświadczenie testowania ciągu długości $n$ = `r n` powrórzono $R= 10^3$. Następnie każdą $p$-wartości z testowania pierwszopoziomowego przekształcono funkcją $f_k$,
a następnie uzyskane w ten sposób wektory połączono jeden, na którym przeprowadzono *Frequency Monobit Test*. Wyniki dla wybranych $k$ przedstawiono w poniższej tabeli.

```{r sqrt2 FM test wynik lvl2}
reps = 10^4
n = floor(length(sqrt2_bist)/reps)

d=as.data.frame(matrix(c(0,0,0),ncol=3))
colnames(d)<- c('Bts len','Test statistic', 'p-value')
lens = 1:15
for(i in 1:length(lens)){
  len=lens[i]
  t = irrationals_FM.test.lvl2(n, reps, sqrt2_bist, len)
  d[i,] <- unname(c(len,t)) 
}
```

```{r sqrt2 FM test wynik lvl2 table}
d$'p-value' <- as.character(signif(d$'p-value'))
d[d$'p-value' =='0',3] <- '0.0000000'
colnames(d) <- c('k - długość 1 wektora bitów', "statystyka testowa", 'p-wartość')
knitr::kable(d, caption = "second level testiong - sqrt 2")



```


```{r sqrt2 FM test wynik lvl2 chi sq}
sq2_p_vals = irrationals_FM.test.p_vals(n, reps, sqrt2_bist)
sq2_p_vals_chisq = chisq.test.unif(sq2_p_vals,10)
```

Ostatecznie dla większości $k$ uzyskane $p$-wartości przeważnie są bardzo małe, a często autmatycznie zaokrąglone przez komputer do zera, choć dla $k =8$ $p$-wartość przekroczyła 0.4, a dla  $k =10$ wyniosła aż ponad 0.7. Przy ustalonym poziomie istotności $\alpha = 0.05$ w większości przypadków hipoteza zerowa zostanie jednak odrzucona.

Ponadto gdy $p$-wartości otrzymane podczas pierwszopoziomowego testowania poddano testowi $\chi^2$ z 10 jednakowymi kubełkami, finalna $p$-wartość wyniosła mniej niż $2.2\cdot10^{-16}$.

Można zatem stwierdzić, że mimo dobrych wyników uzyskanych podczas *first level testing*, ostatecznie należy uznać, że bitów liczby $\sqrt 2$ nie można traktować jako dobry generator liczb z rozkładu jednostajnego na zbiorze {0,1}.


# Źródła
https://ipsec.pl/files/ipsec/ving-krypto.pdf   str 7

"Theory and Practice of Monte Carlo Methods" 
Paweł Lorek Tomasz Rolski

https://pl.wikipedia.org/wiki/RC4

dokumentacja R

https://pl.wikipedia.org/wiki/Mersenne_Twister

